#!/usr/bin/env python3
"""
OpenAIé£æ ¼ChatCompletionæ¥å£ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ChatCompletionæ¥å£è¿›è¡Œå·¥å…·è°ƒç”¨
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__)))

from nanovllm import LLM
from nanovllm.chat_completion import create_chat_completion
import json


def main():
    print("ğŸš€ OpenAIé£æ ¼ChatCompletionæ¥å£ç¤ºä¾‹")
    print("=" * 50)
    
    # åˆå§‹åŒ–LLM
    model_path = "/root/models/Qwen3-0.6B"
    print(f"ğŸ“š åŠ è½½æ¨¡å‹: {model_path}")
    
    llm = LLM(model_path, device="cpu")
    
    # åˆ›å»ºChatCompletionå®ä¾‹
    chat_completion = create_chat_completion(llm)
    
    # å®šä¹‰å·¥å…·ï¼ˆOpenAIæ ¼å¼ï¼‰
    tools = [
        {
            "type": "function",
            "function": {
                "name": "calculate",
                "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "expression": {
                            "type": "string",
                            "description": "è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ '2+3*4'"
                        }
                    },
                    "required": ["expression"]
                }
            }
        },
        {
            "type": "function", 
            "function": {
                "name": "get_weather",
                "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {
                            "type": "string",
                            "description": "åŸå¸‚åç§°"
                        },
                        "unit": {
                            "type": "string",
                            "description": "æ¸©åº¦å•ä½",
                            "enum": ["celsius", "fahrenheit"],
                            "default": "celsius"
                        }
                    },
                    "required": ["city"]
                }
            }
        }
    ]
    
    print("ğŸ› ï¸  å®šä¹‰çš„å·¥å…·:")
    for tool in tools:
        func = tool["function"]
        print(f"  â€¢ {func['name']}: {func['description']}")
    
    print("\n" + "="*50)
    print("ç¤ºä¾‹1: åŸºç¡€å·¥å…·è°ƒç”¨")
    print("="*50)
    
    # ç¤ºä¾‹1: æ•°å­¦è®¡ç®—
    messages = [
        {"role": "user", "content": "è¯·å¸®æˆ‘è®¡ç®— 15 * 8 + 32 çš„ç»“æœ"}
    ]
    
    print("ğŸ‘¤ ç”¨æˆ·:", messages[0]["content"])
    
    response = chat_completion.create(
        messages=messages,
        tools=tools,
        temperature=0.3,
        max_tokens=150
    )
    
    print("ğŸ¤– AIå›å¤:")
    print(f"  å†…å®¹: {response['choices'][0]['message']['content']}")
    print(f"  å®ŒæˆåŸå› : {response['choices'][0]['finish_reason']}")
    
    # æ£€æŸ¥å·¥å…·è°ƒç”¨
    if response['choices'][0]['message'].get('tool_calls'):
        print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨:")
        for call in response['choices'][0]['message']['tool_calls']:
            func = call['function']
            print(f"  â€¢ ID: {call['id']}")
            print(f"  â€¢ å·¥å…·: {func['name']}")
            print(f"  â€¢ å‚æ•°: {func['arguments']}")
    
    print("\n" + "="*50)
    print("ç¤ºä¾‹2: å¤šè½®å¯¹è¯ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰")
    print("="*50)
    
    # ç¤ºä¾‹2: å¤šè½®å¯¹è¯
    conversation = [
        {"role": "user", "content": "è¯·æŸ¥çœ‹åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åå¸®æˆ‘è®¡ç®—ä¸€ä¸‹å¦‚æœæ¸©åº¦æ˜¯25åº¦ï¼Œè½¬æ¢ä¸ºåæ°åº¦æ˜¯å¤šå°‘"}
    ]
    
    print("ğŸ‘¤ ç”¨æˆ·:", conversation[0]["content"])
    
    response = chat_completion.create(
        messages=conversation,
        tools=tools,
        temperature=0.7,
        max_tokens=200
    )
    
    assistant_msg = response['choices'][0]['message']
    conversation.append(assistant_msg)
    
    print("ğŸ¤– AIå›å¤:")
    print(f"  å†…å®¹: {assistant_msg['content']}")
    
    if assistant_msg.get('tool_calls'):
        print("ğŸ”§ å·¥å…·è°ƒç”¨:")
        for call in assistant_msg['tool_calls']:
            func = call['function']
            print(f"  â€¢ {func['name']}({func['arguments']})")
        
        # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œç»“æœ
        tool_results = []
        for call in assistant_msg['tool_calls']:
            func = call['function']
            if func['name'] == 'get_weather':
                tool_results.append({
                    "role": "tool",
                    "tool_call_id": call['id'],
                    "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”ï¼šæ™´å¤©ï¼Œæ°”æ¸©25Â°Cï¼Œæ¹¿åº¦60%"
                })
            elif func['name'] == 'calculate':
                # è§£æå‚æ•°
                args = json.loads(func['arguments'])
                if '25*9/5+32' in args.get('expression', ''):
                    tool_results.append({
                        "role": "tool", 
                        "tool_call_id": call['id'],
                        "content": "è®¡ç®—ç»“æœ: 77.0"
                    })
        
        # æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯
        conversation.extend(tool_results)
        
        # ç»§ç»­å¯¹è¯ï¼Œè®©AIåŸºäºå·¥å…·ç»“æœå›ç­”
        final_response = chat_completion.create(
            messages=conversation,
            temperature=0.7,
            max_tokens=100
        )
        
        print("ğŸ› ï¸  å·¥å…·æ‰§è¡Œåçš„AIå›å¤:")
        print(f"  {final_response['choices'][0]['message']['content']}")
    
    print("\n" + "="*50)
    print("ç¤ºä¾‹3: æµå¼å·¥å…·è°ƒç”¨")
    print("="*50)
    
    messages = [
        {"role": "user", "content": "è¯·è®¡ç®— 100 / 4ï¼Œç„¶åå‘Šè¯‰æˆ‘ç»“æœ"}
    ]
    
    print("ğŸ‘¤ ç”¨æˆ·:", messages[0]["content"])
    print("ğŸ¤– AI (æµå¼): ", end="", flush=True)
    
    # æµå¼è°ƒç”¨
    stream = chat_completion.create(
        messages=messages,
        tools=tools,
        temperature=0.3,
        stream=True
    )
    
    collected_content = ""
    tool_calls_detected = []
    
    for chunk in stream:
        choice = chunk['choices'][0]
        delta = choice['delta']
        
        # è¾“å‡ºæ–‡æœ¬å†…å®¹
        if 'content' in delta and delta['content']:
            print(delta['content'], end='', flush=True)
            collected_content += delta['content']
        
        # æ£€æµ‹å·¥å…·è°ƒç”¨
        if 'tool_calls' in delta:
            tool_calls_detected.extend(delta['tool_calls'])
        
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if choice['finish_reason']:
            print(f"\nâ­ å®ŒæˆåŸå› : {choice['finish_reason']}")
            break
    
    if tool_calls_detected:
        print("ğŸ”§ æµå¼æ£€æµ‹åˆ°çš„å·¥å…·è°ƒç”¨:")
        for call in tool_calls_detected:
            func = call['function']
            print(f"  â€¢ {func['name']}({func['arguments']})")
    
    print("\n" + "="*50)
    print("ç¤ºä¾‹4: å·¥å…·é€‰æ‹©ç­–ç•¥")
    print("="*50)
    
    test_cases = [
        {"tool_choice": "auto", "description": "è‡ªåŠ¨é€‰æ‹©"},
        {"tool_choice": "none", "description": "ä¸ä½¿ç”¨å·¥å…·"},
        {"tool_choice": {"type": "function", "function": {"name": "calculate"}}, "description": "å¼ºåˆ¶ä½¿ç”¨è®¡ç®—å™¨"}
    ]
    
    for case in test_cases:
        print(f"\nğŸ›ï¸  æµ‹è¯• {case['description']}:")
        
        response = chat_completion.create(
            messages=[{"role": "user", "content": "10 + 20 ç­‰äºå¤šå°‘ï¼Ÿ"}],
            tools=tools,
            tool_choice=case["tool_choice"],
            temperature=0.3,
            max_tokens=100
        )
        
        msg = response['choices'][0]['message']
        print(f"  AIå›å¤: {msg['content']}")
        print(f"  å®ŒæˆåŸå› : {response['choices'][0]['finish_reason']}")
        
        if msg.get('tool_calls'):
            print(f"  å·¥å…·è°ƒç”¨: {len(msg['tool_calls'])}ä¸ª")
    
    print("\nâœ¨ æ‰€æœ‰ç¤ºä¾‹å®Œæˆï¼")


if __name__ == "__main__":
    main() 