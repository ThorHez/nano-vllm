from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from typing import Optional, Dict, Any
from langchain_openai import ChatOpenAI
import random
import time
import statistics
from nanovllm.tools.builtin_tools import get_current_time


@tool
def get_weather(city: str) -> Dict[str, Any]:
    """
    è·å–å¤©æ°”ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼‰
    
    Args:
        city: åŸå¸‚åç§°
        
    Returns:
        å¤©æ°”ä¿¡æ¯å­—å…¸
    """
    # è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„å¤©æ°”API
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥è°ƒç”¨çœŸå®çš„å¤©æ°”API
    
    weather_conditions = ["æ™´", "å¤šäº‘", "é˜´", "å°é›¨", "ä¸­é›¨", "å¤§é›¨", "é›ª"]
    
    return {
        "city": city,
        "temperature": random.randint(-10, 35),
        "condition": random.choice(weather_conditions),
        "humidity": random.randint(30, 90),
        "wind_speed": random.randint(0, 20),
        "timestamp": get_current_time()
    }


def create_custom_llm():
    """åˆ›å»ºè‡ªå®šä¹‰LLMå®ä¾‹"""
    # ä½¿ç”¨å­—ç¬¦ä¸²å¹¶å¿½ç•¥ç±»å‹æ£€æŸ¥
    return ChatOpenAI(
        base_url="http://10.239.121.23:8002/v1",
        api_key="EMPTY",  # type: ignore
        model="qwen3_32b",
        temperature=0.0
    )


def example_react_single():
    """å•æ¬¡æ‰§è¡ŒReact Agent"""
    print("ğŸ¤– åˆå§‹åŒ–React Agent...")
    
    # åˆ›å»ºLLMå®ä¾‹
    llm = create_custom_llm()
    
    # å®šä¹‰å·¥å…·åˆ—è¡¨
    tools = [
        get_weather,
    ]
    
    # åˆ›å»ºReact Agent
    agent = create_react_agent(llm, tools)
    
    print("âœ… React Agentåˆ›å»ºæˆåŠŸï¼")
    print("\nå¯ç”¨å·¥å…·:")
    for tool in tools:
        print(f"  - {tool.name}: {tool.description}")
    
    # æ‰§è¡Œå•æ¬¡æŸ¥è¯¢
    response = agent.invoke({"messages": [("user", "What is the weather in Beijing and Tokyo?")]})
    print(f"\nğŸ¤– å“åº”: {response}")
    
    return response


def example_react():
    """ç»Ÿè®¡example_reactè°ƒç”¨å¹³å‡æ—¶é•¿å’ŒAIMessageå“åº”é•¿åº¦"""
    print("ğŸ“Š å¼€å§‹ç»Ÿè®¡React Agentè°ƒç”¨æ—¶é•¿å’ŒAIMessageå“åº”é•¿åº¦...")
    print("=" * 60)
    
    # æµ‹è¯•å‚æ•°
    test_runs = 10  # æµ‹è¯•æ¬¡æ•°
    queries = [
        "What is the weather in Beijing and Tokyo?",
    ]
    
    execution_times = []
    response_lengths = []  # è®°å½•AIMessageå“åº”é•¿åº¦
    ai_message_counts = []  # è®°å½•AIMessageæ•°é‡
    
    # é¢„çƒ­ï¼šå…ˆåˆ›å»ºä¸€æ¬¡Agenté¿å…åˆå§‹åŒ–æ—¶é—´å½±å“æµ‹è¯•
    print("ğŸ”¥ é¢„çƒ­Agent...")
    llm = create_custom_llm()
    tools = [get_weather]
    agent = create_react_agent(llm, tools)
    
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {test_runs} æ¬¡æµ‹è¯•...")
    
    for i in range(test_runs):
        query = queries[i % len(queries)]
        print(f"\nğŸ“ æµ‹è¯• {i+1}/{test_runs}: {query}")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        try:
            # æ‰§è¡ŒAgentè°ƒç”¨
            response = agent.invoke({"messages": [("user", query)]})
            
            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            execution_time = end_time - start_time
            execution_times.append(execution_time)
            
            # è®°å½•å“åº”é•¿åº¦ - ç»Ÿè®¡AIMessageçš„æ€»é•¿åº¦
            ai_message_length = 0
            ai_message_count = 0
            
            if 'messages' in response:
                for message in response['messages']:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯AIMessage
                    is_ai_message = False
                    if hasattr(message, 'type') and message.type == 'ai':
                        is_ai_message = True
                    elif hasattr(message, '__class__') and 'AIMessage' in str(message.__class__):
                        is_ai_message = True
                    
                    if is_ai_message:
                        ai_message_count += 1
                        content = getattr(message, 'content', '')
                        ai_message_length += len(content)
            
            response_lengths.append(ai_message_length)
            ai_message_counts.append(ai_message_count)
            
            print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’")
            print(f"ğŸ“„ AIMessageé•¿åº¦: {ai_message_length} å­—ç¬¦ ({ai_message_count} æ¡AIMessage)")
            
            # è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            if i == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                print(f"ğŸ” è°ƒè¯•ä¿¡æ¯: å“åº”åŒ…å« {len(response.get('messages', []))} æ¡æ¶ˆæ¯")
                for j, msg in enumerate(response.get('messages', [])):
                    msg_type = getattr(msg, 'type', 'unknown')
                    msg_class = str(msg.__class__.__name__)
                    msg_length = len(getattr(msg, 'content', ''))
                    print(f"  æ¶ˆæ¯{j+1}: {msg_class} (type: {msg_type}, é•¿åº¦: {msg_length})")
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            continue
    
    # ç»Ÿè®¡åˆ†æ
    if execution_times and response_lengths and ai_message_counts:
        print("\n" + "=" * 60)
        print("ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"âœ… æˆåŠŸæ‰§è¡Œæ¬¡æ•°: {len(execution_times)}")
        
        # æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
        print(f"\nâ±ï¸  æ—¶é—´ç»Ÿè®¡:")
        print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {statistics.mean(execution_times):.3f}ç§’")
        print(f"  æœ€å¿«æ‰§è¡Œæ—¶é—´: {min(execution_times):.3f}ç§’")
        print(f"  æœ€æ…¢æ‰§è¡Œæ—¶é—´: {max(execution_times):.3f}ç§’")
        
        # å“åº”é•¿åº¦ç»Ÿè®¡
        print(f"\nğŸ“„ AIMessageé•¿åº¦ç»Ÿè®¡:")
        print(f"  å¹³å‡AIMessageé•¿åº¦: {statistics.mean(response_lengths):.1f} å­—ç¬¦")
        print(f"  æœ€çŸ­AIMessageé•¿åº¦: {min(response_lengths)} å­—ç¬¦")
        print(f"  æœ€é•¿AIMessageé•¿åº¦: {max(response_lengths)} å­—ç¬¦")
        
        # AIMessageæ•°é‡ç»Ÿè®¡
        print(f"\nğŸ“Š AIMessageæ•°é‡ç»Ÿè®¡:")
        print(f"  å¹³å‡AIMessageæ•°é‡: {statistics.mean(ai_message_counts):.1f} æ¡")
        print(f"  æœ€å°‘AIMessageæ•°é‡: {min(ai_message_counts)} æ¡")
        print(f"  æœ€å¤šAIMessageæ•°é‡: {max(ai_message_counts)} æ¡")
        
        if len(execution_times) > 1:
            print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
            print(f"  æ—¶é—´æ ‡å‡†å·®: {statistics.stdev(execution_times):.3f}ç§’")
            print(f"  æ—¶é—´ä¸­ä½æ•°: {statistics.median(execution_times):.3f}ç§’")
            print(f"  AIMessageé•¿åº¦æ ‡å‡†å·®: {statistics.stdev(response_lengths):.1f} å­—ç¬¦")
            print(f"  AIMessageé•¿åº¦ä¸­ä½æ•°: {statistics.median(response_lengths):.1f} å­—ç¬¦")
            print(f"  AIMessageæ•°é‡æ ‡å‡†å·®: {statistics.stdev(ai_message_counts):.1f} æ¡")
            print(f"  AIMessageæ•°é‡ä¸­ä½æ•°: {statistics.median(ai_message_counts):.1f} æ¡")
        
        # è¯¦ç»†è®°å½•
        print(f"\nğŸ” è¯¦ç»†è®°å½•:")
        for i, (t, l, c) in enumerate(zip(execution_times, response_lengths, ai_message_counts), 1):
            print(f"  ç¬¬{i}æ¬¡: {t:.3f}ç§’, {l} å­—ç¬¦ (AIMessage), {c} æ¡AIMessage")
            
        # æ€§èƒ½åˆ†æ
        print(f"\nğŸ¯ æ€§èƒ½åˆ†æ:")
        avg_time = statistics.mean(execution_times)
        avg_length = statistics.mean(response_lengths)
        
        if avg_time < 1.0:
            print("ğŸš€ å“åº”é€Ÿåº¦: ä¼˜ç§€ (< 1ç§’)")
        elif avg_time < 3.0:
            print("âœ… å“åº”é€Ÿåº¦: è‰¯å¥½ (< 3ç§’)")
        elif avg_time < 5.0:
            print("âš ï¸  å“åº”é€Ÿåº¦: ä¸€èˆ¬ (< 5ç§’)")
        else:
            print("ğŸŒ å“åº”é€Ÿåº¦: éœ€è¦ä¼˜åŒ– (> 5ç§’)")
            
        if avg_length < 500:
            print("ğŸ“ AIMessageé•¿åº¦: ç®€æ´ (< 500å­—ç¬¦)")
        elif avg_length < 1500:
            print("ğŸ“„ AIMessageé•¿åº¦: ä¸­ç­‰ (< 1500å­—ç¬¦)")
        elif avg_length < 3000:
            print("ğŸ“‹ AIMessageé•¿åº¦: è¯¦ç»† (< 3000å­—ç¬¦)")
        else:
            print("ğŸ“š AIMessageé•¿åº¦: å†—é•¿ (> 3000å­—ç¬¦)")
    
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„æ‰§è¡Œè®°å½•")


if __name__ == "__main__":
    example_react()